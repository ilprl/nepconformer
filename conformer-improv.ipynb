{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install wandb to  support logging all the metrices while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in ./myenv/lib/python3.12/site-packages (0.19.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in ./myenv/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./myenv/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./myenv/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in ./myenv/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in ./myenv/lib/python3.12/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./myenv/lib/python3.12/site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in ./myenv/lib/python3.12/site-packages (from wandb) (2.10.4)\n",
      "Requirement already satisfied: pyyaml in ./myenv/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./myenv/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./myenv/lib/python3.12/site-packages (from wandb) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in ./myenv/lib/python3.12/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.12/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: six>=1.4.0 in ./myenv/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./myenv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./myenv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./myenv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./myenv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file to store wandb api in a file named 'api.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filename and the text to be written\n",
    "filename = 'api.txt'\n",
    "text_to_write = \"502da9cf7b700db4af3b8db0979a771fff1634b8\"\n",
    "# Open the file in write mode\n",
    "with open(filename, 'w') as file:\n",
    "    # Write the text to the file\n",
    "    file.write(text_to_write)\n",
    "\n",
    "print(f\"'{filename}' has been created and written with the specified text.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to your wandb account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(\"your_api_key_here\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the API key from 'api.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"api.txt\") as f:\n",
    "    os.environ[\"WANDB_API_KEY\"] = f.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the repository to your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'NeMo' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/NeMo.git "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install other necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pybind11 in ./myenv/lib/python3.12/site-packages (2.13.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in ./myenv/lib/python3.12/site-packages (0.45.1)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.12/site-packages (75.8.0)\n",
      "Requirement already satisfied: pip in ./myenv/lib/python3.12/site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wheel setuptools pip --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in ./myenv/lib/python3.12/site-packages (0.9.3)\n",
      "Requirement already satisfied: pybind11>=2.2 in ./myenv/lib/python3.12/site-packages (from fasttext) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in ./myenv/lib/python3.12/site-packages (from fasttext) (75.8.0)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.12/site-packages (from fasttext) (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nemo_toolkit==2.1.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.24 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (0.27.1)\n",
      "Requirement already satisfied: numba in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.26.0)\n",
      "Requirement already satisfied: onnx>=1.7.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: ruamel.yaml in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (0.18.10)\n",
      "Requirement already satisfied: scikit-learn in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.6.0)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (75.8.0)\n",
      "Requirement already satisfied: tensorboard in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2.18.0)\n",
      "Requirement already satisfied: text-unidecode in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.3)\n",
      "Requirement already satisfied: torch in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (4.67.1)\n",
      "Requirement already satisfied: wget in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.2)\n",
      "Requirement already satisfied: wrapt in ./myenv/lib/python3.12/site-packages (from nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.17.0)\n",
      "Requirement already satisfied: braceexpand in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.1.7)\n",
      "Requirement already satisfied: editdistance in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: einops in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.8.0)\n",
      "Requirement already satisfied: g2p_en in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: jiwer in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (3.0.5)\n",
      "Requirement already satisfied: kaldi-python-io in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (1.2.2)\n",
      "Requirement already satisfied: kaldiio in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (2.18.0)\n",
      "Requirement already satisfied: lhotse>=1.26.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (1.29.0)\n",
      "Requirement already satisfied: librosa>=0.10.2 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.10.2.post1)\n",
      "Requirement already satisfied: marshmallow in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (3.24.2)\n",
      "Requirement already satisfied: optuna in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (4.1.0)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (24.2)\n",
      "Requirement already satisfied: pyannote.core in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (5.0.0)\n",
      "Requirement already satisfied: pyannote.metrics in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: pydub in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.25.1)\n",
      "Requirement already satisfied: pyloudnorm in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.1.1)\n",
      "Requirement already satisfied: resampy in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: soundfile in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.13.0)\n",
      "Requirement already satisfied: sox in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (1.5.0)\n",
      "Requirement already satisfied: texterrors in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.5.1)\n",
      "Requirement already satisfied: cloudpickle in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: fiddle in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.3.0)\n",
      "Requirement already satisfied: hydra-core<=1.3.2,>1.3 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (1.3.2)\n",
      "Requirement already satisfied: lightning<=2.4.0,>2.2.1 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (2.4.0)\n",
      "Requirement already satisfied: omegaconf<=2.3 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (2.3.0)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (1.6.1)\n",
      "Requirement already satisfied: transformers>=4.45.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (4.47.1)\n",
      "Requirement already satisfied: wandb in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.19.2)\n",
      "Requirement already satisfied: webdataset>=0.2.86 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.2.100)\n",
      "Requirement already satisfied: datasets in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: inflect in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (7.5.0)\n",
      "Requirement already satisfied: mediapy==1.1.6 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (1.1.6)\n",
      "Requirement already satisfied: pandas in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (2.2.3)\n",
      "Requirement already satisfied: sacremoses>=0.0.43 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.1.1)\n",
      "Requirement already satisfied: sentencepiece<1.0.0 in ./myenv/lib/python3.12/site-packages (from nemo_toolkit[asr]==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: ipython in ./myenv/lib/python3.12/site-packages (from mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (8.31.0)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.12/site-packages (from mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (3.10.0)\n",
      "Requirement already satisfied: Pillow in ./myenv/lib/python3.12/site-packages (from mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (11.1.0)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.12/site-packages (from huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib/python3.12/site-packages (from huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2024.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.12/site-packages (from huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (6.0.2)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.12/site-packages (from huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.12/site-packages (from huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./myenv/lib/python3.12/site-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit[asr]==2.1.0) (4.9.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./myenv/lib/python3.12/site-packages (from lhotse>=1.26.0->nemo_toolkit[asr]==2.1.0) (3.0.1)\n",
      "Requirement already satisfied: click>=7.1.1 in ./myenv/lib/python3.12/site-packages (from lhotse>=1.26.0->nemo_toolkit[asr]==2.1.0) (8.1.8)\n",
      "Requirement already satisfied: cytoolz>=0.10.1 in ./myenv/lib/python3.12/site-packages (from lhotse>=1.26.0->nemo_toolkit[asr]==2.1.0) (1.0.1)\n",
      "Requirement already satisfied: intervaltree>=3.1.0 in ./myenv/lib/python3.12/site-packages (from lhotse>=1.26.0->nemo_toolkit[asr]==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.1 in ./myenv/lib/python3.12/site-packages (from lhotse>=1.26.0->nemo_toolkit[asr]==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: lilcom>=1.1.0 in ./myenv/lib/python3.12/site-packages (from lhotse>=1.26.0->nemo_toolkit[asr]==2.1.0) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.14 in ./myenv/lib/python3.12/site-packages (from librosa>=0.10.2->nemo_toolkit[asr]==2.1.0) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./myenv/lib/python3.12/site-packages (from librosa>=0.10.2->nemo_toolkit[asr]==2.1.0) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./myenv/lib/python3.12/site-packages (from librosa>=0.10.2->nemo_toolkit[asr]==2.1.0) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./myenv/lib/python3.12/site-packages (from librosa>=0.10.2->nemo_toolkit[asr]==2.1.0) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./myenv/lib/python3.12/site-packages (from librosa>=0.10.2->nemo_toolkit[asr]==2.1.0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./myenv/lib/python3.12/site-packages (from librosa>=0.10.2->nemo_toolkit[asr]==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in ./myenv/lib/python3.12/site-packages (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]==2.1.0) (0.11.9)\n",
      "Requirement already satisfied: pytorch-lightning in ./myenv/lib/python3.12/site-packages (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]==2.1.0) (2.5.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./myenv/lib/python3.12/site-packages (from numba->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (0.43.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./myenv/lib/python3.12/site-packages (from onnx>=1.7.0->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (5.29.3)\n",
      "Requirement already satisfied: regex in ./myenv/lib/python3.12/site-packages (from sacremoses>=0.0.43->nemo_toolkit[asr]==2.1.0) (2024.11.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./myenv/lib/python3.12/site-packages (from soundfile->nemo_toolkit[asr]==2.1.0) (1.17.1)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./myenv/lib/python3.12/site-packages (from torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.12/site-packages (from sympy==1.13.1->torch->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./myenv/lib/python3.12/site-packages (from transformers>=4.45.0->nemo_toolkit[asr]==2.1.0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./myenv/lib/python3.12/site-packages (from transformers>=4.45.0->nemo_toolkit[asr]==2.1.0) (0.5.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./myenv/lib/python3.12/site-packages (from datasets->nemo_toolkit[asr]==2.1.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./myenv/lib/python3.12/site-packages (from datasets->nemo_toolkit[asr]==2.1.0) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./myenv/lib/python3.12/site-packages (from datasets->nemo_toolkit[asr]==2.1.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./myenv/lib/python3.12/site-packages (from datasets->nemo_toolkit[asr]==2.1.0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./myenv/lib/python3.12/site-packages (from datasets->nemo_toolkit[asr]==2.1.0) (3.11.11)\n",
      "Requirement already satisfied: absl-py in ./myenv/lib/python3.12/site-packages (from fiddle->nemo_toolkit[asr]==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: graphviz in ./myenv/lib/python3.12/site-packages (from fiddle->nemo_toolkit[asr]==2.1.0) (0.20.3)\n",
      "Requirement already satisfied: libcst in ./myenv/lib/python3.12/site-packages (from fiddle->nemo_toolkit[asr]==2.1.0) (1.5.1)\n",
      "Requirement already satisfied: nltk>=3.2.4 in ./myenv/lib/python3.12/site-packages (from g2p_en->nemo_toolkit[asr]==2.1.0) (3.9.1)\n",
      "Requirement already satisfied: distance>=0.1.3 in ./myenv/lib/python3.12/site-packages (from g2p_en->nemo_toolkit[asr]==2.1.0) (0.1.3)\n",
      "Requirement already satisfied: more_itertools>=8.5.0 in ./myenv/lib/python3.12/site-packages (from inflect->nemo_toolkit[asr]==2.1.0) (10.5.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in ./myenv/lib/python3.12/site-packages (from inflect->nemo_toolkit[asr]==2.1.0) (4.4.1)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in ./myenv/lib/python3.12/site-packages (from jiwer->nemo_toolkit[asr]==2.1.0) (3.11.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./myenv/lib/python3.12/site-packages (from optuna->nemo_toolkit[asr]==2.1.0) (1.14.0)\n",
      "Requirement already satisfied: colorlog in ./myenv/lib/python3.12/site-packages (from optuna->nemo_toolkit[asr]==2.1.0) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in ./myenv/lib/python3.12/site-packages (from optuna->nemo_toolkit[asr]==2.1.0) (2.0.36)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas->nemo_toolkit[asr]==2.1.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas->nemo_toolkit[asr]==2.1.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.17.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in ./myenv/lib/python3.12/site-packages (from pyannote.core->nemo_toolkit[asr]==2.1.0) (2.4.0)\n",
      "Requirement already satisfied: pyannote.database>=4.0.1 in ./myenv/lib/python3.12/site-packages (from pyannote.metrics->nemo_toolkit[asr]==2.1.0) (5.1.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in ./myenv/lib/python3.12/site-packages (from pyannote.metrics->nemo_toolkit[asr]==2.1.0) (0.6.2)\n",
      "Requirement already satisfied: future>=0.16.0 in ./myenv/lib/python3.12/site-packages (from pyloudnorm->nemo_toolkit[asr]==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./myenv/lib/python3.12/site-packages (from ruamel.yaml->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (0.2.12)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./myenv/lib/python3.12/site-packages (from tensorboard->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (1.69.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./myenv/lib/python3.12/site-packages (from tensorboard->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./myenv/lib/python3.12/site-packages (from tensorboard->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./myenv/lib/python3.12/site-packages (from tensorboard->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.1.3)\n",
      "Requirement already satisfied: pybind11 in ./myenv/lib/python3.12/site-packages (from texterrors->nemo_toolkit[asr]==2.1.0) (2.13.6)\n",
      "Requirement already satisfied: plac in ./myenv/lib/python3.12/site-packages (from texterrors->nemo_toolkit[asr]==2.1.0) (1.4.3)\n",
      "Requirement already satisfied: loguru in ./myenv/lib/python3.12/site-packages (from texterrors->nemo_toolkit[asr]==2.1.0) (0.7.3)\n",
      "Requirement already satisfied: termcolor in ./myenv/lib/python3.12/site-packages (from texterrors->nemo_toolkit[asr]==2.1.0) (2.5.0)\n",
      "Requirement already satisfied: Levenshtein in ./myenv/lib/python3.12/site-packages (from texterrors->nemo_toolkit[asr]==2.1.0) (0.26.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./myenv/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.1.0) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./myenv/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.1.0) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in ./myenv/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.1.0) (4.3.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./myenv/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.1.0) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in ./myenv/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.1.0) (2.10.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./myenv/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.1.0) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in ./myenv/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.1.0) (1.3.4)\n",
      "Requirement already satisfied: Mako in ./myenv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna->nemo_toolkit[asr]==2.1.0) (1.3.8)\n",
      "Requirement already satisfied: pycparser in ./myenv/lib/python3.12/site-packages (from cffi>=1.0->soundfile->nemo_toolkit[asr]==2.1.0) (2.22)\n",
      "Requirement already satisfied: toolz>=0.8.0 in ./myenv/lib/python3.12/site-packages (from cytoolz>=0.10.1->lhotse>=1.26.0->nemo_toolkit[asr]==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./myenv/lib/python3.12/site-packages (from aiohttp->datasets->nemo_toolkit[asr]==2.1.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./myenv/lib/python3.12/site-packages (from aiohttp->datasets->nemo_toolkit[asr]==2.1.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv/lib/python3.12/site-packages (from aiohttp->datasets->nemo_toolkit[asr]==2.1.0) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./myenv/lib/python3.12/site-packages (from aiohttp->datasets->nemo_toolkit[asr]==2.1.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./myenv/lib/python3.12/site-packages (from aiohttp->datasets->nemo_toolkit[asr]==2.1.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./myenv/lib/python3.12/site-packages (from aiohttp->datasets->nemo_toolkit[asr]==2.1.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./myenv/lib/python3.12/site-packages (from aiohttp->datasets->nemo_toolkit[asr]==2.1.0) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./myenv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]==2.1.0) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.12/site-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.12/site-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.12/site-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: typer>=0.12.1 in ./myenv/lib/python3.12/site-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.1.0) (0.15.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb->nemo_toolkit[asr]==2.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./myenv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb->nemo_toolkit[asr]==2.1.0) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.24->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./myenv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna->nemo_toolkit[asr]==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./myenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard->nemo_toolkit==2.1.0->nemo_toolkit[asr]==2.1.0) (3.0.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myenv/lib/python3.12/site-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./myenv/lib/python3.12/site-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myenv/lib/python3.12/site-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./myenv/lib/python3.12/site-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./myenv/lib/python3.12/site-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./myenv/lib/python3.12/site-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./myenv/lib/python3.12/site-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (5.14.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./myenv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]==2.1.0) (5.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./myenv/lib/python3.12/site-packages (from jedi>=0.16->ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myenv/lib/python3.12/site-packages (from pexpect>4.3->ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./myenv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.2.13)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./myenv/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.1.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./myenv/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.1.0) (13.9.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myenv/lib/python3.12/site-packages (from stack_data->ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myenv/lib/python3.12/site-packages (from stack_data->ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./myenv/lib/python3.12/site-packages (from stack_data->ipython->mediapy==1.1.6->nemo_toolkit[asr]==2.1.0) (0.2.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.1.0) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.1.0) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nemo_toolkit['asr']==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import nemo\n",
    "\n",
    "print(nemo.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some files from NeMo are rewritten here because NeMo wasn't able to read them from the local NeMo folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File NeMo/examples/asr/asr_ctc/speech_to_text_ctc_bpe.py has been updated.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"NeMo/examples/asr/asr_ctc/speech_to_text_ctc_bpe.py\"\n",
    "\n",
    "# The new content to write to the file\n",
    "new_content = '''\n",
    "# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "# Preparing the Tokenizer for the dataset\n",
    "Use the `process_asr_text_tokenizer.py` script under <NEMO_ROOT>/scripts/tokenizers/ in order to prepare the tokenizer.\n",
    "\n",
    "```sh\n",
    "python <NEMO_ROOT>/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "        --manifest=<path to train manifest files, seperated by commas>\n",
    "        OR\n",
    "        --data_file=<path to text data, seperated by commas> \\\n",
    "        --data_root=\"<output directory>\" \\\n",
    "        --vocab_size=<number of tokens in vocabulary> \\\n",
    "        --tokenizer=<\"spe\" or \"wpe\"> \\\n",
    "        --no_lower_case \\\n",
    "        --spe_type=<\"unigram\", \"bpe\", \"char\" or \"word\"> \\\n",
    "        --spe_character_coverage=1.0 \\\n",
    "        --log\n",
    "```\n",
    "\n",
    "# Training the model\n",
    "```sh\n",
    "python speech_to_text_ctc_bpe.py \\\n",
    "    # (Optional: --config-path=<path to dir of configs> --config-name=<name of config without .yaml>) \\\n",
    "    model.train_ds.manifest_filepath=<path to train manifest> \\\n",
    "    model.validation_ds.manifest_filepath=<path to val/test manifest> \\\n",
    "    model.tokenizer.dir=<path to directory of tokenizer (not full path to the vocab file!)> \\\n",
    "    model.tokenizer.type=<either bpe or wpe> \\\n",
    "    trainer.devices=-1 \\\n",
    "    trainer.accelerator=\"gpu\" \\\n",
    "    trainer.strategy=\"ddu\"\n",
    "    trainer.max_epochs=100 \\\n",
    "    model.optim.name=\"adamw\" \\\n",
    "    model.optim.lr=0.001 \\\n",
    "    model.optim.betas=[0.9,0.999] \\\n",
    "    model.optim.weight_decay=0.0001 \\\n",
    "    model.optim.sched.warmup_steps=2000\n",
    "    exp_manager.create_wandb_logger=True \\\n",
    "    exp_manager.wandb_logger_kwargs.name=\"<Name of experiment>\" \\\n",
    "    exp_manager.wandb_logger_kwargs.project=\"<Name of project>\"\n",
    "```\n",
    "\n",
    "# Fine-tune a model\n",
    "\n",
    "For documentation on fine-tuning this model, please visit -\n",
    "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/configs.html#fine-tuning-configurations\n",
    "\n",
    "# Pretrained Models\n",
    "\n",
    "For documentation on existing pretrained models, please visit -\n",
    "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/results.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nemo.collections.asr.models.ctc_bpe_models import EncDecCTCModelBPE\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "# Path to trainer_utils.py\n",
    "file_path = \"NeMo/nemo/utils/trainer_utils.py\"\n",
    "\n",
    "# Load the module from the file path\n",
    "spec = importlib.util.spec_from_file_location(\"trainer_utils\", file_path)\n",
    "trainer_utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(trainer_utils)\n",
    "\n",
    "# Now you can use resolve_trainer_cfg\n",
    "resolve_trainer_cfg = trainer_utils.resolve_trainer_cfg\n",
    "\n",
    "@hydra_runner(config_path=\"../conf/citrinet/\", config_name=\"config_bpe\")\n",
    "def main(cfg):\n",
    "    logging.info(f'Hydra config: {OmegaConf.to_yaml(cfg)}')\n",
    "\n",
    "    trainer = pl.Trainer(**resolve_trainer_cfg(cfg.trainer))\n",
    "    exp_manager(trainer, cfg.get(\"exp_manager\", None))\n",
    "    asr_model = EncDecCTCModelBPE(cfg=cfg.model, trainer=trainer)\n",
    "\n",
    "    # Initialize the weights of the model from another model, if provided via config\n",
    "    asr_model.maybe_init_from_pretrained_checkpoint(cfg)\n",
    "\n",
    "    trainer.fit(asr_model)\n",
    "\n",
    "    if hasattr(cfg.model, 'test_ds') and cfg.model.test_ds.manifest_filepath is not None:\n",
    "        if asr_model.prepare_test(trainer):\n",
    "            trainer.test(asr_model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "'''\n",
    "\n",
    "# Open the file in write mode and overwrite the content\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(new_content)\n",
    "    \n",
    "print(f\"File {file_path} has been updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the config.yaml file as it eases the process of trying different values for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.yaml file has been created.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "config = \"\"\"\n",
    "name: \"Conformer-CTC-BPE\"\n",
    "\n",
    "model:\n",
    "  sample_rate: 16000\n",
    "  log_prediction: true\n",
    "  ctc_reduction: 'mean_batch'\n",
    "  skip_nan_grad: false\n",
    "\n",
    "  train_ds:\n",
    "    manifest_filepath: ???\n",
    "    sample_rate: ${model.sample_rate}\n",
    "    batch_size: 16\n",
    "    shuffle: true\n",
    "    num_workers: 8\n",
    "    pin_memory: true\n",
    "    max_duration: 16.7\n",
    "    min_duration: 0.1\n",
    "    is_tarred: false\n",
    "    tarred_audio_filepaths: null\n",
    "    shuffle_n: 2048\n",
    "    bucketing_strategy: \"synced_randomized\"\n",
    "    bucketing_batch_size: null\n",
    "\n",
    "  validation_ds:\n",
    "    manifest_filepath: ???\n",
    "    sample_rate: ${model.sample_rate}\n",
    "    batch_size: 16\n",
    "    shuffle: false\n",
    "    use_start_end_token: false\n",
    "    num_workers: 8\n",
    "    pin_memory: true\n",
    "\n",
    "  test_ds:\n",
    "    manifest_filepath: null\n",
    "    sample_rate: ${model.sample_rate}\n",
    "    batch_size: 16\n",
    "    shuffle: false\n",
    "    use_start_end_token: false\n",
    "    num_workers: 8\n",
    "    pin_memory: true\n",
    "\n",
    "  tokenizer:\n",
    "    dir: ???\n",
    "    type: bpe\n",
    "\n",
    "  preprocessor:\n",
    "    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n",
    "    sample_rate: ${model.sample_rate}\n",
    "    normalize: \"per_feature\"\n",
    "    window_size: 0.025\n",
    "    window_stride: 0.01\n",
    "    window: \"hann\"\n",
    "    features: 80\n",
    "    n_fft: 512\n",
    "    log: true\n",
    "    frame_splicing: 1\n",
    "    dither: 0.00001\n",
    "    pad_to: 0\n",
    "    pad_value: 0.0\n",
    "\n",
    "  spec_augment:\n",
    "    _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
    "    freq_masks: 2\n",
    "    time_masks: 10\n",
    "    freq_width: 27\n",
    "    time_width: 0.05\n",
    "\n",
    "  encoder:\n",
    "    _target_: nemo.collections.asr.modules.ConformerEncoder\n",
    "    feat_in: ${model.preprocessor.features}\n",
    "    feat_out: -1\n",
    "    n_layers: 18\n",
    "    d_model: 256\n",
    "    subsampling: striding\n",
    "    subsampling_factor: 4\n",
    "    subsampling_conv_channels: -1\n",
    "    causal_downsampling: false\n",
    "    ff_expansion_factor: 4\n",
    "    self_attention_model: rel_pos\n",
    "    n_heads: 4\n",
    "    att_context_size: [-1, -1]\n",
    "    att_context_style: regular\n",
    "    xscaling: true\n",
    "    untie_biases: true\n",
    "    pos_emb_max_len: 5000\n",
    "    conv_kernel_size: 31\n",
    "    conv_norm_type: 'batch_norm'\n",
    "    conv_context_size: null\n",
    "    dropout: 0.1\n",
    "    dropout_pre_encoder: 0.1\n",
    "    dropout_emb: 0.0\n",
    "    dropout_att: 0.1\n",
    "    stochastic_depth_drop_prob: 0.0\n",
    "    stochastic_depth_mode: linear\n",
    "    stochastic_depth_start_layer: 1\n",
    "\n",
    "  decoder:\n",
    "    _target_: nemo.collections.asr.modules.ConvASRDecoder\n",
    "    feat_in: null\n",
    "    num_classes: -1\n",
    "    vocabulary: []\n",
    "\n",
    "  interctc:\n",
    "    loss_weights: []\n",
    "    apply_at_layers: []\n",
    "\n",
    "  optim:\n",
    "    name: adamw\n",
    "    lr: 0.4\n",
    "    betas: [0.9, 0.98]\n",
    "    weight_decay: 1e-3\n",
    "    sched:\n",
    "      name: NoamAnnealing\n",
    "      d_model: ${model.encoder.d_model}\n",
    "      warmup_steps: 10000\n",
    "      warmup_ratio: null\n",
    "      min_lr: 1e-6\n",
    "\n",
    "trainer:\n",
    "  devices: -1\n",
    "  num_nodes: 1\n",
    "  max_epochs: 50\n",
    "  max_steps: -1\n",
    "  val_check_interval: 1.0\n",
    "  accelerator: auto\n",
    "  \n",
    "  accumulate_grad_batches: 1\n",
    "  gradient_clip_val: 0.0\n",
    "  precision: 32\n",
    "  log_every_n_steps: 10\n",
    "  enable_progress_bar: True\n",
    "  num_sanity_val_steps: 0\n",
    "  check_val_every_n_epoch: 1\n",
    "  sync_batchnorm: true\n",
    "  enable_checkpointing: False\n",
    "  logger: false\n",
    "  benchmark: false\n",
    "\n",
    "exp_manager:\n",
    "  exp_dir: null\n",
    "  name: ${name}\n",
    "  create_tensorboard_logger: true\n",
    "  create_checkpoint_callback: true\n",
    "  checkpoint_callback_params:\n",
    "    monitor: \"val_wer\"\n",
    "    mode: \"min\"\n",
    "    save_top_k: 5\n",
    "    always_save_nemo: True\n",
    "  \n",
    "  resume_if_exists: false\n",
    "  resume_ignore_no_checkpoint: false\n",
    "  create_wandb_logger: True\n",
    "  wandb_logger_kwargs:\n",
    "    name: \"lr-0.4\"\n",
    "    project: \"Conformer0.4_FULL\"\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "with open('config.yaml', 'w') as file:\n",
    "    file.write(config)\n",
    "\n",
    "print(\"config.yaml file has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '''\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import tokenizers\n",
    "\n",
    "from nemo.collections.common.tokenizers.sentencepiece_tokenizer import create_spt_model\n",
    "from nemo.utils.data_utils import DataStoreObject\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Create tokenizer')\n",
    "group = parser.add_mutually_exclusive_group(required=True)\n",
    "group.add_argument(\"--manifest\", default=None, type=str, help='Comma separated list of manifest files')\n",
    "group.add_argument(\"--data_file\", default=None, help='data file from which to create tokenizer model')\n",
    "parser.add_argument(\"--data_root\", required=True, default=None, type=str, help='Output directory')\n",
    "parser.add_argument(\"--vocab_size\", default=1024, type=int, help='Vocabulary size')\n",
    "parser.add_argument(\"--tokenizer\", default=\"wpe\", choices=[\"spe\", \"wpe\"], help='Type of tokenization to perform')\n",
    "parser.add_argument(\n",
    "    \"--spe_type\",\n",
    "    default=\"bpe\",\n",
    "    choices=['bpe', 'unigram', 'char', 'word'],\n",
    "    help='Type of the SentencePiece model. Can be `bpe`, `unigram`, `char` or `word`.'\n",
    "    'Used only if --tokenizer == `spe`',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--spe_character_coverage',\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    help=\"Character coverage percentage for SentencePiece tokenization. For languages \"\n",
    "    \"with large vocabulary, should be close to 0.9995, otherwise kept as 1.0\",\n",
    ")\n",
    "parser.add_argument('--spe_bos', action='store_true', help='Add <s> token to SentencePiece Tokenizer.')\n",
    "parser.add_argument('--spe_eos', action='store_true', help='Add </s> token to SentencePiece Tokenizer.')\n",
    "parser.add_argument('--spe_pad', action='store_true', help='Add <pad> token to SentencePiece Tokenizer.')\n",
    "parser.add_argument(\n",
    "    '--spe_user_defined_symbols', default=None, type=str, nargs='+', help='User defined symbols for SentencePiece'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--spe_control_symbols', default=None, type=str, nargs='+', help='Control symbols for SentencePiece'\n",
    ")\n",
    "parser.add_argument('--spe_split_digits', action='store_true', help='Split digits into separate tokens.')\n",
    "parser.add_argument(\n",
    "    '--spe_remove_extra_whitespaces',\n",
    "    action='store_true',\n",
    "    help='Remove leading, trailing, and duplicate internal whitespace.',\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--spe_sample_size',\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help=\"Samples the dataset by `sample_size` if positive integer, otherwise uses whole dataset\",\n",
    ")\n",
    "parser.add_argument('--spe_train_extremely_large_corpus', action='store_true', help='')\n",
    "parser.add_argument(\n",
    "    '--spe_max_sentencepiece_length',\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help='Limit the maximum number of tokens in each SentencePiece subword. '\n",
    "    'Must be a positive integer > 0. By default places no limit on subword length.',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--spe_no_split_by_unicode_script',\n",
    "    dest='spe_split_by_unicode_script',\n",
    "    action='store_false',\n",
    "    help=\"Don't use Unicode script to split sentence pieces.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--spe_byte_fallback',\n",
    "    dest='spe_byte_fallback',\n",
    "    action='store_true',\n",
    "    help=\"If <unk>, fallback to a byte sequence of the characters.\",\n",
    ")\n",
    "parser.add_argument('--no_lower_case', dest='lower_case', action='store_false')\n",
    "parser.add_argument(\"--log\", action='store_true')\n",
    "parser.set_defaults(log=False, lower_case=True, spe_train_extremely_large_corpus=False)\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "def __build_document_from_manifests(\n",
    "    data_root: str,\n",
    "    manifests: str,\n",
    "):\n",
    "    if ',' in manifests:\n",
    "        manifests = manifests.split(',')\n",
    "    else:\n",
    "        manifests = [manifests]\n",
    "\n",
    "    document_dir = os.path.join(data_root, 'text_corpus')\n",
    "    if not os.path.exists(document_dir):\n",
    "        os.makedirs(document_dir)\n",
    "\n",
    "    document_path = os.path.join(document_dir, 'document.txt')\n",
    "\n",
    "    if os.path.exists(document_path):\n",
    "        logging.info('Corpus already exists at path : %s', document_path)\n",
    "        return document_path\n",
    "\n",
    "    num_lines = 0\n",
    "    with open(document_path, 'w') as out_writer:\n",
    "        for manifest in manifests:\n",
    "            with open(DataStoreObject(manifest).get(), 'r') as in_reader:\n",
    "                for line in in_reader:\n",
    "                    item = json.loads(line)\n",
    "                    text = item['text']\n",
    "\n",
    "                    out_writer.write(text + '\\\\n')\n",
    "                    out_writer.flush()\n",
    "\n",
    "                    num_lines += 1\n",
    "\n",
    "            logging.info(f\"Finished extracting manifest : {manifest}\")\n",
    "\n",
    "        logging.info(\"Finished extracting all manifests ! Number of sentences : {}\".format(num_lines))\n",
    "    return document_path\n",
    "\n",
    "\n",
    "def __process_data(\n",
    "    text_path: str,\n",
    "    dst_folder: str,\n",
    "    vocab_size: int,\n",
    "    tokenizer_type: str,\n",
    "    spe_type: str,\n",
    "    spe_character_coverage: float,\n",
    "    spe_train_extremely_large_corpus: bool,\n",
    "    spe_sample_size: int,\n",
    "    spe_max_sentencepiece_length: int,\n",
    "    spe_split_by_unicode_script: bool,\n",
    "    spe_bos: bool,\n",
    "    spe_eos: bool,\n",
    "    spe_pad: bool,\n",
    "    spe_control_symbols: Optional[List[str]],\n",
    "    spe_user_defined_symbols: Optional[List[str]],\n",
    "    spe_byte_fallback: bool,\n",
    "    spe_split_digits: bool,\n",
    "    spe_remove_extra_whitespaces: bool,\n",
    "    lower_case: bool,\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts flac to wav and build manifests's json\n",
    "    Args:\n",
    "        text_path: source with text lines\n",
    "        dst_folder: where wav files will be stored\n",
    "        vocab_size: vocabular size used in encoding the text\n",
    "        tokenizer_type: type of tokenization to perform - wpe or spe\n",
    "        spe_type: type of tokenization model used for spe.\n",
    "        spe_character_coverage: float value between 0 and 1 (as a percentage). For languages with a vast charset,\n",
    "            can be < 1.0, but for all other languages, it should be set as 1.0\n",
    "        spe_sample_size: int, default of -1. If positive integer is used, samples the dataset\n",
    "            by given sample size.\n",
    "        spe_train_extremely_large_corpus: bool. If dataset is too large, and user has sufficient RAM,\n",
    "            this flag can be set to try to trained the tokenizer. Will silently fail if it runs out of RAM.\n",
    "        spe_max_sentencepiece_length: Limits the maximum length of the SentencePiece subword that can be constructed.\n",
    "            By default, no limit is placed.\n",
    "        spe_bos: Bool flag, whether to add <s> to SentencePiece tokenizer vocabulary.\n",
    "        spe_eos: Bool flag, whether to add </s> to SentencePiece tokenizer vocabulary.\n",
    "        spe_pad: Bool flag, whether to add <pad> to SentencePiece tokenizer vocabulary.\n",
    "        spe_control_symbols: control symbols to add to tokenizer, as defined by sentencepiece.\n",
    "            These tokens get removed at decode time and are not encoded from the text - can only be added to the input programatically.\n",
    "        spe_user_defined_symbols: user symbols to add to tokenizer, as defined by sentencepiece.\n",
    "            These tokens remain in the decoded text and are encoded automatically when present in the input text.\n",
    "        spe_byte_fallback: If <unk>, fallback to a byte sequence of the character.\n",
    "        spe_split_digits: If true, digits are split into individual tokens.\n",
    "        spe_remove_extra_whitespaces: If true, removes leading, trailing, and duplicate internal whitespace.\n",
    "        lower_case: whether to tokenize with lower case character set only (for english)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if tokenizer_type == 'spe':\n",
    "\n",
    "        # Prepare directory of tokenizer\n",
    "        if spe_max_sentencepiece_length > 0:\n",
    "            tokenizer_dir = os.path.join(dst_folder, 'tokenizer_{}_{}_v{}_max_{}').format(\n",
    "                tokenizer_type, spe_type, vocab_size, spe_max_sentencepiece_length\n",
    "            )\n",
    "        else:\n",
    "            tokenizer_dir = os.path.join(dst_folder, 'tokenizer_{}_{}_v{}').format(\n",
    "                tokenizer_type, spe_type, vocab_size\n",
    "            )\n",
    "\n",
    "        if spe_pad:\n",
    "            tokenizer_dir = f'{tokenizer_dir}_pad'\n",
    "        if spe_bos:\n",
    "            tokenizer_dir = f'{tokenizer_dir}_bos'\n",
    "        if spe_eos:\n",
    "            tokenizer_dir = f'{tokenizer_dir}_eos'\n",
    "\n",
    "        if not os.path.exists(tokenizer_dir):\n",
    "            os.makedirs(tokenizer_dir)\n",
    "\n",
    "        if os.path.exists(os.path.join(tokenizer_dir, 'tokenizer.model')):\n",
    "            logging.warning(\"Model file already exists, overriding old model file !\")\n",
    "            os.remove(os.path.join(tokenizer_dir, 'tokenizer.model'))\n",
    "\n",
    "        # Build tokenizer\n",
    "        tokenizer_path, vocab_path = create_spt_model(\n",
    "            data_file=text_path,\n",
    "            vocab_size=vocab_size,\n",
    "            sample_size=spe_sample_size,\n",
    "            do_lower_case=lower_case,\n",
    "            output_dir=tokenizer_dir,\n",
    "            tokenizer_type=spe_type,\n",
    "            character_coverage=spe_character_coverage,\n",
    "            train_extremely_large_corpus=spe_train_extremely_large_corpus,\n",
    "            max_sentencepiece_length=spe_max_sentencepiece_length,\n",
    "            split_by_unicode_script=spe_split_by_unicode_script,\n",
    "            bos=spe_bos,\n",
    "            eos=spe_eos,\n",
    "            pad=spe_pad,\n",
    "            control_symbols=spe_control_symbols,\n",
    "            user_defined_symbols=spe_user_defined_symbols,\n",
    "            byte_fallback=spe_byte_fallback,\n",
    "            split_digits=spe_split_digits,\n",
    "            \n",
    "        )\n",
    "\n",
    "    else:\n",
    "        tokenizer_dir = os.path.join(dst_folder, 'tokenizer_{}_v{}').format(tokenizer_type, vocab_size)\n",
    "\n",
    "        if not os.path.exists(tokenizer_dir):\n",
    "            os.makedirs(tokenizer_dir)\n",
    "\n",
    "        tokenizer = tokenizers.BertWordPieceTokenizer(lowercase=lower_case)\n",
    "\n",
    "        tokenizer.train(text_path, vocab_size=vocab_size)\n",
    "        tokenizer.save_model(tokenizer_dir)\n",
    "\n",
    "    return tokenizer_dir\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_root = args.data_root\n",
    "    manifests = args.manifest\n",
    "    data_file = args.data_file\n",
    "    vocab_size = args.vocab_size\n",
    "    tokenizer = args.tokenizer\n",
    "    spe_type = args.spe_type\n",
    "    spe_character_coverage = args.spe_character_coverage\n",
    "    spe_sample_size = args.spe_sample_size\n",
    "    spe_train_extremely_large_corpus = args.spe_train_extremely_large_corpus\n",
    "    spe_max_sentencepiece_length = args.spe_max_sentencepiece_length\n",
    "    spe_split_by_unicode_script = args.spe_split_by_unicode_script\n",
    "    spe_bos, spe_eos, spe_pad = args.spe_bos, args.spe_eos, args.spe_pad\n",
    "    spe_control_symbols = args.spe_control_symbols\n",
    "    spe_user_defined_symbols = args.spe_user_defined_symbols\n",
    "    spe_byte_fallback = args.spe_byte_fallback\n",
    "    spe_split_digits = args.spe_split_digits\n",
    "    spe_remove_extra_whitespaces = args.spe_remove_extra_whitespaces\n",
    "    lower_case = args.lower_case\n",
    "\n",
    "    # Get the data\n",
    "    if not data_file:\n",
    "        document_path = __build_document_from_manifests(\n",
    "            data_root=data_root,\n",
    "            manifests=manifests\n",
    "        )\n",
    "    else:\n",
    "        document_path = data_file\n",
    "\n",
    "    # Process and create the tokenizer\n",
    "    tokenizer_dir = __process_data(\n",
    "        text_path=document_path,\n",
    "        dst_folder=data_root,\n",
    "        vocab_size=vocab_size,\n",
    "        tokenizer_type=tokenizer,\n",
    "        spe_type=spe_type,\n",
    "        spe_character_coverage=spe_character_coverage,\n",
    "        spe_train_extremely_large_corpus=spe_train_extremely_large_corpus,\n",
    "        spe_sample_size=spe_sample_size,\n",
    "        spe_max_sentencepiece_length=spe_max_sentencepiece_length,\n",
    "        spe_split_by_unicode_script=spe_split_by_unicode_script,\n",
    "        spe_bos=spe_bos,\n",
    "        spe_eos=spe_eos,\n",
    "        spe_pad=spe_pad,\n",
    "        spe_control_symbols=spe_control_symbols,\n",
    "        spe_user_defined_symbols=spe_user_defined_symbols,\n",
    "        spe_byte_fallback=spe_byte_fallback,\n",
    "        spe_split_digits=spe_split_digits,\n",
    "        spe_remove_extra_whitespaces=spe_remove_extra_whitespaces,\n",
    "        lower_case=lower_case,\n",
    "    )\n",
    "    logging.info('Created tokenizer model in directory : %s', tokenizer_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open('NeMo/scripts/tokenizers/process_asr_text_tokenizer.py', 'w') as f:\n",
    "    f.write(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File NeMo/nemo/collections/common/tokenizers/canary_tokenizer.py has been updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\|'\n",
      "/tmp/ipykernel_371344/291663513.py:4: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  new_content = '''\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"NeMo/nemo/collections/common/tokenizers/canary_tokenizer.py\"\n",
    "\n",
    "# The new content to write to the file\n",
    "new_content = '''\n",
    "# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import os\n",
    "import re\n",
    "from functools import cached_property\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "from nemo.collections.common.tokenizers.aggregate_tokenizer import AggregateTokenizer\n",
    "from nemo.collections.common.tokenizers.sentencepiece_tokenizer import SentencePieceTokenizer, create_spt_model\n",
    "\n",
    "from nemo.utils import logging\n",
    "\n",
    "__all__ = ['CanaryTokenizer']\n",
    "\n",
    "# Default tokens for compatibility with Canary.\n",
    "CANARY_BOS = \"<|startoftranscript|>\"\n",
    "CANARY_EOS = \"<|endoftext|>\"\n",
    "CANARY_PAD = \"<pad>\"\n",
    "CANARY_NOSPEECH = \"<|nospeech|>\"\n",
    "CANARY_PNC = \"<|pnc|>\"\n",
    "CANARY_NOPNC = \"<|nopnc|>\"\n",
    "CANARY2_BOCTX = \"<|startofcontext|>\"\n",
    "DEFAULT_TOKENS = [CANARY_NOSPEECH, CANARY_PAD, CANARY_EOS, CANARY_BOS, CANARY_PNC, CANARY_NOPNC]\n",
    "\n",
    "CANARY_SPECIAL_TOKENIZER = \"spl_tokens\"\n",
    "\n",
    "\n",
    "class CanaryTokenizer(AggregateTokenizer):\n",
    "    \"\"\"\n",
    "    Thin wrapper around AggregateTokenizer to provide quick access to special tokens\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizers: Dict):\n",
    "        super().__init__(tokenizers)\n",
    "\n",
    "        # for easy access of special tokens\n",
    "        self.special_tokens = {}\n",
    "        for special in tokenizers[CANARY_SPECIAL_TOKENIZER].vocab:\n",
    "            # Search for special prompting tokens\n",
    "            if (special.startswith(\"<|\") and special.endswith(\"|>\")) or special == CANARY_PAD:\n",
    "                self.special_tokens[special] = self.token_to_id(special, lang_id=CANARY_SPECIAL_TOKENIZER)\n",
    "\n",
    "    @cached_property\n",
    "    def eos_id(self) -> int:\n",
    "        return self.special_tokens[CANARY_EOS]\n",
    "\n",
    "    @cached_property\n",
    "    def bos_id(self) -> int:\n",
    "        return self.special_tokens[CANARY_BOS]\n",
    "\n",
    "    @cached_property\n",
    "    def nospeech_id(self) -> int:\n",
    "        return self.special_tokens[CANARY_NOSPEECH]\n",
    "\n",
    "    @cached_property\n",
    "    def pad_id(self) -> int:\n",
    "        return self.special_tokens[CANARY_PAD]\n",
    "\n",
    "    def _text_with_timestamps_to_ids(self, text_without_timestamps, time_text, lang_id) -> list[int]:\n",
    "        trans_words = text_without_timestamps.split()\n",
    "\n",
    "        # Get timestamp ids\n",
    "        time_ids = self._tokenize_special_prompt(time_text)\n",
    "\n",
    "        # Tokenize text word by wordd\n",
    "        word_ids = []\n",
    "        result_ids = []\n",
    "        time_index = 0\n",
    "\n",
    "        timestamp_every_n_words = 1  # Add timestmap for every N words\n",
    "        word_index = 0\n",
    "        # Both start and end time\n",
    "        for word in trans_words:\n",
    "            # Insert the first time_id once\n",
    "            if word_index == 0 and time_index < len(time_ids):\n",
    "                result_ids.append(time_ids[time_index])\n",
    "                time_index += 1\n",
    "            # Tokenize the word\n",
    "            word_ids += super().text_to_ids(word, lang_id)\n",
    "            result_ids += super().text_to_ids(word, lang_id)\n",
    "            word_index += 1\n",
    "            # Insert time ids every N words after the first one\n",
    "            if word_index % timestamp_every_n_words == 0 and word_index != 0 and time_index < len(time_ids):\n",
    "                result_ids.append(time_ids[time_index])\n",
    "                time_index += 1\n",
    "                if time_index < len(time_ids):\n",
    "                    result_ids.append(time_ids[time_index])\n",
    "                    time_index += 1\n",
    "            else:\n",
    "                time_index += 2\n",
    "        # Ensure the last time_id is appended at the end\n",
    "        if time_index < len(time_ids):\n",
    "            result_ids.append(time_ids[-1])\n",
    "        # Make sure the last time_id is appended only once\n",
    "        if time_index < len(time_ids) and result_ids[-1] != (time_ids[-1]):\n",
    "            result_ids.append(time_ids[-1])\n",
    "        return result_ids\n",
    "\n",
    "    def _text_to_ids_maybe_with_timestamps(self, text_no_eos, lang_id) -> list[int]:\n",
    "        time_pattern = re.compile(r\"<\\|\\d+\\|>\")\n",
    "        time_text = \"\".join(time_pattern.findall(text_no_eos))\n",
    "        has_timestamp = bool(time_text)\n",
    "        if not has_timestamp:\n",
    "            return super().text_to_ids(text_no_eos, lang_id)\n",
    "        else:\n",
    "            text_without_timestamps = time_pattern.sub(\"\", text_no_eos).strip()\n",
    "            return self._text_with_timestamps_to_ids(text_without_timestamps, time_text, lang_id)\n",
    "\n",
    "    def text_to_ids(self, text, lang_id) -> list[int]:\n",
    "        if lang_id == CANARY_SPECIAL_TOKENIZER:\n",
    "            return self._tokenize_special_prompt(text)\n",
    "        lang_id = _map_canary1_to_canary2_lang(lang_id, self.langs)\n",
    "        if text.endswith(CANARY_EOS):\n",
    "            return self._text_to_ids_maybe_with_timestamps(text[: -len(CANARY_EOS)], lang_id) + [self.eos_id]\n",
    "        return self._text_to_ids_maybe_with_timestamps(text, lang_id)\n",
    "\n",
    "    def _tokenize_special_prompt(self, text: str) -> list[int]:\n",
    "        \"\"\"\n",
    "        Tokenize the input special prompt of Canary family of models.\n",
    "\n",
    "        Required because otherwise self.text_to_ids() returns a different result than what Canary had been trained with.\n",
    "        \"\"\"\n",
    "        ans = []\n",
    "\n",
    "        if text.startswith(CANARY2_BOCTX):\n",
    "            # Canary 2 prompt format. It starts with decoder context, which should be tokenized using\n",
    "            # a different tokenizer than spl_tokens. We don't really know what it is, so we'll use the\n",
    "            # following HACK solution: look up 5th token which is target_lang and tokenize this part\n",
    "            # using its tokenizer. We skip this when decoder context is empty.\n",
    "            ans.append(self.special_tokens[CANARY2_BOCTX])\n",
    "            text = text[len(CANARY2_BOCTX) :]\n",
    "            ctx_end_idx = text.find(CANARY_BOS)\n",
    "            if decoder_ctx := text[:ctx_end_idx]:\n",
    "                target_lang = text.split(\"<|\")[4].replace(\"|>\", \"\")  # sorry\n",
    "                ans.extend(self.text_to_ids(decoder_ctx, target_lang))\n",
    "                text = text[ctx_end_idx:]\n",
    "\n",
    "        num_special_tokens = text.count(\">\")\n",
    "        for _ in range(num_special_tokens):\n",
    "            token = text[: text.find(\">\") + 1]\n",
    "            ans.append(self.special_tokens[token])\n",
    "            text = text[len(token) :]\n",
    "        assert len(text) == 0, text\n",
    "        return ans\n",
    "\n",
    "    def spl_token_to_id(self, token):\n",
    "        if token_id := self.special_tokens.get(f\"<|{token}|>\", None):\n",
    "            return token_id\n",
    "        raise KeyError(f\"Token {token} not found in tokenizer.\")\n",
    "    from typing import Union\n",
    "    @staticmethod\n",
    "    def build_special_tokenizer(\n",
    "        tokens: List[str], model_dir: Union[str, Path], force_rebuild: bool = False\n",
    "    ) -> SentencePieceTokenizer:\n",
    "        if force_rebuild:\n",
    "            logging.info(\"Building special tokenizer\")\n",
    "            # Checks for artifacts of previous build.\n",
    "            for file in [\"tokenizer.model\", \"tokenizer.vocab\", \"vocab.txt\", \"train_text.txt\"]:\n",
    "                if os.path.exists(file):\n",
    "                    os.remove(file)\n",
    "        spl_tok_re = re.compile(r\"<\\|.+\\|>\")\n",
    "        tokens = DEFAULT_TOKENS + [f\"<|{t}|>\" if spl_tok_re.match(t) is None else t for t in tokens]\n",
    "        tokens = list(dict.fromkeys(tokens))  # remove duplicates while preserving order\n",
    "        output_dir = Path(model_dir)\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        text_path = output_dir / \"train_text.txt\"\n",
    "        train_text = \"\\n\".join(tokens)\n",
    "        text_path.write_text(train_text)\n",
    "        model_path = output_dir / \"tokenizer.model\"\n",
    "        create_spt_model(\n",
    "            str(text_path),\n",
    "            vocab_size=len(tokens) + 2,\n",
    "            sample_size=-1,\n",
    "            do_lower_case=False,\n",
    "            output_dir=str(output_dir),\n",
    "            user_defined_symbols=tokens,\n",
    "        )\n",
    "        spl_tokenizer = SentencePieceTokenizer(str(model_path))\n",
    "        return spl_tokenizer\n",
    "\n",
    "\n",
    "def _map_canary1_to_canary2_lang(lang: str, available_langs: list[str]) -> str:\n",
    "    if len(lang) != 2 or lang in available_langs:\n",
    "        return lang\n",
    "\n",
    "    if (\n",
    "        mapped := {\"en\": \"en-US\", \"es\": \"es-ES\", \"fr\": \"fr-FR\", \"de\": \"de-DE\"}.get(lang)\n",
    "    ) is not None and mapped in available_langs:\n",
    "        return mapped\n",
    "\n",
    "    raise RuntimeError(f\"Unsupported language: '{lang}' for CanaryTokenizer with languages: {available_langs}\")\n",
    "'''\n",
    "\n",
    "# Open the file in write mode and overwrite the content\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(new_content)\n",
    "    \n",
    "print(f\"File {file_path} has been updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data using process_asr_text_tokenizer.py from NeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model file already exists, overriding old model file !\n",
      "[NeMo I 2025-01-10 10:06:32 nemo_logging:393] Processing tokens/text_corpus/document.txt and store at tokens/tokenizer_spe_unigram_v128_max_200\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=tokens/text_corpus/document.txt --model_prefix=tokens/tokenizer_spe_unigram_v128_max_200/tokenizer --vocab_size=128 --shuffle_input_sentence=true --hard_vocab_limit=false --model_type=unigram --character_coverage=1.0 --bos_id=-1 --eos_id=-1 --normalization_rule_name=nmt_nfkc_cf --max_sentencepiece_length=200 --remove_extra_whitespaces=false\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: tokens/text_corpus/document.txt\n",
      "  input_format: \n",
      "  model_prefix: tokens/tokenizer_spe_unigram_v128_max_200/tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 128\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 200\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:   \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc_cf\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 0\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: tokens/text_corpus/document.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 141873 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=2734014\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=93\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 141873 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=1470150\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 111938 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 141873\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 47506\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 47506 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=36237 obj=11.7967 num_tokens=81510 num_tokens/piece=2.24936\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=30125 obj=9.9571 num_tokens=81754 num_tokens/piece=2.71383\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=22586 obj=9.97692 num_tokens=87896 num_tokens/piece=3.89161\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=22573 obj=9.93493 num_tokens=87902 num_tokens/piece=3.89412\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=16929 obj=10.1518 num_tokens=96489 num_tokens/piece=5.69963\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=16927 obj=10.0882 num_tokens=96516 num_tokens/piece=5.7019\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12695 obj=10.381 num_tokens=105398 num_tokens/piece=8.30232\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12695 obj=10.3048 num_tokens=105499 num_tokens/piece=8.31028\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9521 obj=10.6644 num_tokens=115088 num_tokens/piece=12.0878\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9521 obj=10.5814 num_tokens=115098 num_tokens/piece=12.0889\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=7140 obj=10.9948 num_tokens=125158 num_tokens/piece=17.5291\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=7140 obj=10.91 num_tokens=125158 num_tokens/piece=17.5291\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5355 obj=11.378 num_tokens=134809 num_tokens/piece=25.1744\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5355 obj=11.2865 num_tokens=134811 num_tokens/piece=25.1748\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=4016 obj=11.8062 num_tokens=145006 num_tokens/piece=36.1071\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=4016 obj=11.7069 num_tokens=145011 num_tokens/piece=36.1083\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3012 obj=12.2804 num_tokens=155339 num_tokens/piece=51.5734\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3012 obj=12.1685 num_tokens=155342 num_tokens/piece=51.5744\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2259 obj=12.8157 num_tokens=166346 num_tokens/piece=73.637\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2259 obj=12.6876 num_tokens=166355 num_tokens/piece=73.641\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1694 obj=13.3955 num_tokens=177378 num_tokens/piece=104.71\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1694 obj=13.2568 num_tokens=177379 num_tokens/piece=104.71\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1270 obj=13.9863 num_tokens=189773 num_tokens/piece=149.428\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1270 obj=13.8306 num_tokens=189774 num_tokens/piece=149.428\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=952 obj=14.6042 num_tokens=202369 num_tokens/piece=212.572\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=952 obj=14.4437 num_tokens=202370 num_tokens/piece=212.574\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=714 obj=15.2621 num_tokens=214554 num_tokens/piece=300.496\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=714 obj=15.086 num_tokens=214567 num_tokens/piece=300.514\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=535 obj=15.9843 num_tokens=226076 num_tokens/piece=422.572\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=535 obj=15.7931 num_tokens=226084 num_tokens/piece=422.587\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=401 obj=16.6929 num_tokens=241090 num_tokens/piece=601.222\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=401 obj=16.4752 num_tokens=241118 num_tokens/piece=601.292\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=300 obj=17.4211 num_tokens=256517 num_tokens/piece=855.057\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=300 obj=17.1825 num_tokens=256517 num_tokens/piece=855.057\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=225 obj=18.2825 num_tokens=269078 num_tokens/piece=1195.9\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=225 obj=18.0117 num_tokens=269078 num_tokens/piece=1195.9\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=168 obj=19.2023 num_tokens=288544 num_tokens/piece=1717.52\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=168 obj=18.8772 num_tokens=288544 num_tokens/piece=1717.52\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=140 obj=19.9047 num_tokens=306864 num_tokens/piece=2191.89\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=140 obj=19.5625 num_tokens=306864 num_tokens/piece=2191.89\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: tokens/tokenizer_spe_unigram_v128_max_200/tokenizer.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: tokens/tokenizer_spe_unigram_v128_max_200/tokenizer.vocab\n"
     ]
    }
   ],
   "source": [
    "!python NeMo/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "    --manifest \"dataset/manifest_labels_train.json\" \\\n",
    "    --data_root \"tokens\" \\\n",
    "    --vocab_size 128 \\\n",
    "    --tokenizer \"spe\" \\\n",
    "    --spe_type \"unigram\" \\\n",
    "    --spe_max_sentencepiece_length 200 \\\n",
    "    --spe_character_coverage 1.0 \\\n",
    "    --log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.0 in ./myenv/lib/python3.12/site-packages (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-01-10 10:06:44 nemo_logging:405] /home/jenny/conformer/myenv/lib/python3.12/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] Hydra config: name: Conformer-CTC-BPE\n",
      "    model:\n",
      "      sample_rate: 16000\n",
      "      log_prediction: true\n",
      "      ctc_reduction: mean_batch\n",
      "      skip_nan_grad: false\n",
      "      train_ds:\n",
      "        manifest_filepath: dataset/manifest_labels_train.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: true\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        max_duration: 16.7\n",
      "        min_duration: 0.1\n",
      "        is_tarred: false\n",
      "        tarred_audio_filepaths: null\n",
      "        shuffle_n: 2048\n",
      "        bucketing_strategy: synced_randomized\n",
      "        bucketing_batch_size: null\n",
      "      validation_ds:\n",
      "        manifest_filepath: dataset/manifest_labels_val.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      test_ds:\n",
      "        manifest_filepath: dataset/manifest_remaining_test.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      tokenizer:\n",
      "        dir: tokens/tokenizer_spe_unigram_v128_max_200\n",
      "        type: bpe\n",
      "      preprocessor:\n",
      "        _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        normalize: per_feature\n",
      "        window_size: 0.025\n",
      "        window_stride: 0.01\n",
      "        window: hann\n",
      "        features: 80\n",
      "        n_fft: 512\n",
      "        log: true\n",
      "        frame_splicing: 1\n",
      "        dither: 1.0e-05\n",
      "        pad_to: 0\n",
      "        pad_value: 0.0\n",
      "      spec_augment:\n",
      "        _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "        freq_masks: 2\n",
      "        time_masks: 10\n",
      "        freq_width: 27\n",
      "        time_width: 0.05\n",
      "      encoder:\n",
      "        _target_: nemo.collections.asr.modules.ConformerEncoder\n",
      "        feat_in: ${model.preprocessor.features}\n",
      "        feat_out: -1\n",
      "        n_layers: 18\n",
      "        d_model: 256\n",
      "        subsampling: striding\n",
      "        subsampling_factor: 4\n",
      "        subsampling_conv_channels: -1\n",
      "        causal_downsampling: false\n",
      "        ff_expansion_factor: 4\n",
      "        self_attention_model: rel_pos\n",
      "        n_heads: 4\n",
      "        att_context_size:\n",
      "        - -1\n",
      "        - -1\n",
      "        att_context_style: regular\n",
      "        xscaling: true\n",
      "        untie_biases: true\n",
      "        pos_emb_max_len: 5000\n",
      "        conv_kernel_size: 31\n",
      "        conv_norm_type: batch_norm\n",
      "        conv_context_size: null\n",
      "        dropout: 0.1\n",
      "        dropout_pre_encoder: 0.1\n",
      "        dropout_emb: 0.0\n",
      "        dropout_att: 0.1\n",
      "        stochastic_depth_drop_prob: 0.0\n",
      "        stochastic_depth_mode: linear\n",
      "        stochastic_depth_start_layer: 1\n",
      "      decoder:\n",
      "        _target_: nemo.collections.asr.modules.ConvASRDecoder\n",
      "        feat_in: null\n",
      "        num_classes: -1\n",
      "        vocabulary: []\n",
      "      interctc:\n",
      "        loss_weights: []\n",
      "        apply_at_layers: []\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 0.4\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        weight_decay: 0.001\n",
      "        sched:\n",
      "          name: NoamAnnealing\n",
      "          d_model: ${model.encoder.d_model}\n",
      "          warmup_steps: 10000\n",
      "          warmup_ratio: null\n",
      "          min_lr: 1.0e-06\n",
      "    trainer:\n",
      "      devices: -1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 50\n",
      "      max_steps: -1\n",
      "      val_check_interval: 1.0\n",
      "      accelerator: auto\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      log_every_n_steps: 10\n",
      "      enable_progress_bar: true\n",
      "      num_sanity_val_steps: 0\n",
      "      check_val_every_n_epoch: 1\n",
      "      sync_batchnorm: true\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "      benchmark: false\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_wer\n",
      "        mode: min\n",
      "        save_top_k: 5\n",
      "        always_save_nemo: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_wandb_logger: true\n",
      "      wandb_logger_kwargs:\n",
      "        name: Conformerexp4-lr-0.4\n",
      "        project: Conformer_bpe_FULL\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] ExpManager schema\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] {'explicit_log_dir': None, 'exp_dir': None, 'name': None, 'version': None, 'use_datetime_version': True, 'resume_if_exists': False, 'resume_past_end': False, 'resume_ignore_no_checkpoint': False, 'resume_from_checkpoint': None, 'create_tensorboard_logger': True, 'summary_writer_kwargs': None, 'create_wandb_logger': False, 'wandb_logger_kwargs': None, 'create_mlflow_logger': False, 'mlflow_logger_kwargs': {'experiment_name': None, 'tracking_uri': None, 'tags': None, 'save_dir': './mlruns', 'prefix': '', 'artifact_location': None, 'run_id': None, 'log_model': False}, 'create_dllogger_logger': False, 'dllogger_logger_kwargs': {'verbose': False, 'stdout': False, 'json_file': './dllogger.json'}, 'create_clearml_logger': False, 'clearml_logger_kwargs': {'project': None, 'task': None, 'connect_pytorch': False, 'model_name': None, 'tags': None, 'log_model': False, 'log_cfg': False, 'log_metrics': False}, 'create_neptune_logger': False, 'neptune_logger_kwargs': None, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'filepath': None, 'dirpath': None, 'filename': None, 'monitor': 'val_loss', 'verbose': True, 'save_last': True, 'save_top_k': 3, 'save_weights_only': False, 'mode': 'min', 'auto_insert_metric_name': True, 'every_n_epochs': 1, 'every_n_train_steps': None, 'train_time_interval': None, 'prefix': None, 'postfix': '.nemo', 'save_best_model': False, 'always_save_nemo': False, 'save_nemo_on_train_end': True, 'model_parallel_size': None, 'save_on_train_epoch_end': False, 'async_save': False, 'save_last_n_optim_states': -1}, 'create_early_stopping_callback': False, 'early_stopping_callback_params': {'monitor': 'val_loss', 'mode': 'min', 'min_delta': 0.001, 'patience': 10, 'verbose': True, 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None, 'log_rank_zero_only': False}, 'create_preemption_callback': True, 'files_to_copy': None, 'log_step_timing': True, 'log_delta_step_timing': False, 'step_timing_kwargs': {'reduction': 'mean', 'sync_cuda': False, 'buffer_size': 1}, 'log_local_rank_0_only': False, 'log_global_rank_0_only': False, 'disable_validation_on_resume': True, 'ema': {'enable': False, 'decay': 0.999, 'cpu_offload': False, 'validate_original_weights': False, 'every_n_steps': 1}, 'max_time_per_run': None, 'seconds_to_sleep': 5.0, 'create_straggler_detection_callback': False, 'straggler_detection_params': {'report_time_interval': 300.0, 'calc_relative_gpu_perf': True, 'calc_individual_gpu_perf': True, 'num_gpu_perf_scores_to_log': 5, 'gpu_relative_perf_threshold': 0.7, 'gpu_individual_perf_threshold': 0.7, 'stop_if_detected': False}, 'create_fault_tolerance_callback': False, 'fault_tolerance': {'workload_check_interval': 5.0, 'initial_rank_heartbeat_timeout': 3600.0, 'rank_heartbeat_timeout': 2700.0, 'calculate_timeouts': True, 'safety_factor': 5.0, 'rank_termination_signal': <Signals.SIGKILL: 9>, 'log_level': 'INFO', 'max_rank_restarts': 0, 'max_subsequent_job_failures': 0, 'additional_ft_launcher_args': '', 'simulated_fault': None}, 'log_tflops_per_sec_per_gpu': True}\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] Experiments will be logged at /home/jenny/conformer/nemo_experiments/Conformer-CTC-BPE/2025-01-10_10-06-44\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] TensorboardLogger has been set up\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] WandBLogger has been set up\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] TFLOPs per sec per GPU will be calculated, conditioned on supported models. Defaults to -1 upon failure.\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n",
      "[NeMo I 2025-01-10 10:06:44 nemo_logging:393] \n",
      "    Replacing placeholder number of classes (-1) with actual number of classes - 128\n",
      "[NeMo I 2025-01-10 10:06:47 nemo_logging:393] Dataset loaded with 141861 files totalling 73.74 hours\n",
      "[NeMo I 2025-01-10 10:06:47 nemo_logging:393] 12 files were filtered totalling 0.07 hours\n",
      "[NeMo I 2025-01-10 10:06:47 nemo_logging:393] Dataset loaded with 1603 files totalling 0.83 hours\n",
      "[NeMo I 2025-01-10 10:06:47 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-01-10 10:06:47 nemo_logging:393] Dataset loaded with 14428 files totalling 7.53 hours\n",
      "[NeMo I 2025-01-10 10:06:47 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-01-10 10:06:47 nemo_logging:393] PADDING: 0\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjp39041720\u001b[0m (\u001b[33mjp39041720-kathamandu-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/jenny/conformer/nemo_experiments/wandb/run-20250110_100649-2025-01-10_10-06-44\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mConformerexp4-lr-0.4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/jp39041720-kathamandu-university/Conformer_bpe_FULL\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/jp39041720-kathamandu-university/Conformer_bpe_FULL/runs/2025-01-10_10-06-44\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2025-01-10 10:06:51 nemo_logging:393] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.4\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2025-01-10 10:06:51 nemo_logging:393] Scheduler \"<nemo.core.optim.lr_scheduler.NoamAnnealing object at 0x703ad1f8d820>\" \n",
      "    will be used during training (effective maximum steps = 443350) - \n",
      "    Parameters : \n",
      "    (d_model: 256\n",
      "    warmup_steps: 10000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-06\n",
      "    max_steps: 443350\n",
      "    )\n",
      "\n",
      "  | Name              | Type                              | Params | Mode \n",
      "--------------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
      "1 | encoder           | ConformerEncoder                  | 30.5 M | train\n",
      "2 | decoder           | ConvASRDecoder                    | 33.2 K | train\n",
      "3 | loss              | CTCLoss                           | 0      | train\n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
      "5 | wer               | WER                               | 0      | train\n",
      "--------------------------------------------------------------------------------\n",
      "30.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.5 M    Total params\n",
      "122.154   Total estimated model params size (MB)\n",
      "524       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Training: |                                               | 0/? [00:00<?, ?it/s][NeMo I 2025-01-10 10:06:51 nemo_logging:393] Preemption requires torch distributed to be initialized, disabling preemption\n",
      "Epoch 0:   0%| | 9/8867 [00:02<44:00,  3.35it/s, v_num=6-44, train_step_timing i[NeMo I 2025-01-10 10:06:54 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:06:54 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:06:54 nemo_logging:393] predicted:k.a    ke !  a. !   \n",
      "Epoch 0:   0%| | 19/8867 [00:03<30:28,  4.84it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:06:55 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:06:55 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:06:55 nemo_logging:393] predicted:?    \n",
      "Epoch 0:   0%| | 29/8867 [00:05<27:00,  5.45it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:06:56 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:06:56 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:06:56 nemo_logging:393] predicted:!.c    .c    \n",
      "Epoch 0:   0%| | 39/8867 [00:06<25:55,  5.67it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:06:58 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:06:58 nemo_logging:393] reference:       \n",
      "[NeMo I 2025-01-10 10:06:58 nemo_logging:393] predicted:   ?  ?k  ? .    \n",
      "Epoch 0:   1%| | 49/8867 [00:08<24:16,  6.05it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:06:59 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:06:59 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:06:59 nemo_logging:393] predicted: ka    k\n",
      "Epoch 0:   1%| | 59/8867 [00:09<23:19,  6.30it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:07:00 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:00 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:00 nemo_logging:393] predicted:c .! \n",
      "Epoch 0:   1%| | 69/8867 [00:10<22:42,  6.46it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:07:02 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:02 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:02 nemo_logging:393] predicted:\n",
      "Epoch 0:   1%| | 79/8867 [00:11<22:10,  6.61it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:07:03 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:03 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:07:03 nemo_logging:393] predicted:\n",
      "Epoch 0:   1%| | 89/8867 [00:13<21:39,  6.75it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:07:04 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:04 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:07:04 nemo_logging:393] predicted:\n",
      "Epoch 0:   1%| | 99/8867 [00:14<21:13,  6.89it/s, v_num=6-44, train_step_timing [NeMo I 2025-01-10 10:07:05 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:05 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:05 nemo_logging:393] predicted:\n",
      "Epoch 0:   1%| | 109/8867 [00:15<21:00,  6.95it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:07 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:07 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:07:07 nemo_logging:393] predicted:\n",
      "Epoch 0:   1%| | 119/8867 [00:17<20:51,  6.99it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:08 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:08 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:08 nemo_logging:393] predicted:\n",
      "Epoch 0:   1%| | 129/8867 [00:18<20:40,  7.05it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:09 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:09 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:07:09 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 139/8867 [00:19<20:26,  7.12it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:11 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:11 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:11 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 149/8867 [00:20<20:10,  7.20it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:12 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:12 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:07:12 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 159/8867 [00:21<19:58,  7.26it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:13 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:13 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:13 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 169/8867 [00:23<19:46,  7.33it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:14 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:14 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:14 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 179/8867 [00:24<19:35,  7.39it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:15 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:15 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:15 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 189/8867 [00:25<19:28,  7.43it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:16 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:16 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:16 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 199/8867 [00:26<19:19,  7.48it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:18 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:18 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:18 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 209/8867 [00:28<19:20,  7.46it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:19 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:19 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:19 nemo_logging:393] predicted:\n",
      "Epoch 0:   2%| | 219/8867 [00:29<19:13,  7.50it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:20 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:20 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:20 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 229/8867 [00:30<19:08,  7.52it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:21 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:21 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:21 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 239/8867 [00:31<19:03,  7.54it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:23 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:23 nemo_logging:393] reference:       \n",
      "[NeMo I 2025-01-10 10:07:23 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 249/8867 [00:32<18:58,  7.57it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:24 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:24 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:07:24 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 259/8867 [00:34<18:56,  7.57it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:25 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:25 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:25 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 269/8867 [00:35<18:55,  7.57it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:26 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:26 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:26 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 279/8867 [00:36<18:53,  7.57it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:28 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:28 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:28 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 289/8867 [00:38<18:47,  7.61it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:29 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:29 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:07:29 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 299/8867 [00:39<18:45,  7.61it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:30 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:30 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:30 nemo_logging:393] predicted:\n",
      "Epoch 0:   3%| | 309/8867 [00:40<18:39,  7.65it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:31 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:31 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:31 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 319/8867 [00:41<18:37,  7.65it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:33 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:33 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:07:33 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 329/8867 [00:43<18:36,  7.65it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:34 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:34 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:34 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 339/8867 [00:44<18:33,  7.66it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:35 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:35 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:35 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 349/8867 [00:45<18:32,  7.66it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:37 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:37 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:37 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 359/8867 [00:46<18:33,  7.64it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:38 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:38 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:38 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 369/8867 [00:48<18:31,  7.65it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:39 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:39 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:39 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 379/8867 [00:49<18:28,  7.66it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:40 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:40 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:40 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 389/8867 [00:50<18:25,  7.67it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:42 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:42 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:07:42 nemo_logging:393] predicted:\n",
      "Epoch 0:   4%| | 399/8867 [00:52<18:27,  7.65it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:43 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:43 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:43 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 409/8867 [00:53<18:24,  7.66it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:44 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:44 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:44 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 419/8867 [00:54<18:22,  7.66it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:46 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:46 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:46 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 429/8867 [00:56<18:23,  7.65it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:47 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:47 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:47 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 439/8867 [00:57<18:23,  7.64it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:49 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:49 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:49 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 449/8867 [00:58<18:22,  7.64it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:50 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:50 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:07:50 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 459/8867 [00:59<18:18,  7.65it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:51 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:51 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:51 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 469/8867 [01:01<18:14,  7.67it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:52 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:52 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:07:52 nemo_logging:393] predicted:\n",
      "Epoch 0:   5%| | 479/8867 [01:02<18:12,  7.68it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:53 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:53 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:53 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 489/8867 [01:03<18:08,  7.70it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:55 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:55 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:55 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 499/8867 [01:04<18:05,  7.71it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:56 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:56 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:56 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 509/8867 [01:05<18:03,  7.71it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:57 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:57 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:57 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 519/8867 [01:07<18:00,  7.72it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:07:58 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:07:58 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:07:58 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 529/8867 [01:08<18:05,  7.68it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:00 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:00 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:00 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 539/8867 [01:10<18:05,  7.67it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:01 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:01 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:01 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 549/8867 [01:11<18:03,  7.68it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:02 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:02 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:02 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 559/8867 [01:12<17:59,  7.69it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:04 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:04 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:04 nemo_logging:393] predicted:\n",
      "Epoch 0:   6%| | 569/8867 [01:14<18:01,  7.67it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:05 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:05 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:05 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 579/8867 [01:15<18:01,  7.66it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:07 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:07 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:07 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 589/8867 [01:16<17:58,  7.67it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:08 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:08 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:08 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 599/8867 [01:18<17:57,  7.67it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:09 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:09 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:09 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 609/8867 [01:19<17:54,  7.68it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:10 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:10 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:10 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 619/8867 [01:20<17:51,  7.70it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:11 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:11 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:11 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 629/8867 [01:21<17:51,  7.69it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:13 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:13 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:13 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 639/8867 [01:22<17:48,  7.70it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:14 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:14 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:14 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 649/8867 [01:24<17:45,  7.72it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:15 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:15 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:15 nemo_logging:393] predicted:\n",
      "Epoch 0:   7%| | 659/8867 [01:25<17:42,  7.73it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:16 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:16 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:16 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 669/8867 [01:26<17:40,  7.73it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:18 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:18 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:18 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 679/8867 [01:27<17:37,  7.74it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:19 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:19 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:08:19 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 689/8867 [01:28<17:35,  7.75it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:20 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:20 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:20 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 699/8867 [01:30<17:34,  7.75it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:21 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:21 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:21 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 709/8867 [01:31<17:31,  7.76it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:22 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:22 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:22 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 719/8867 [01:32<17:29,  7.76it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:24 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:24 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:24 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 729/8867 [01:33<17:27,  7.77it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:25 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:25 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:25 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 739/8867 [01:35<17:26,  7.77it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:26 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:26 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:26 nemo_logging:393] predicted:\n",
      "Epoch 0:   8%| | 749/8867 [01:36<17:25,  7.76it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:27 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:27 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:27 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 759/8867 [01:37<17:25,  7.75it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:29 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:29 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:29 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 769/8867 [01:39<17:25,  7.75it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:30 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:30 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:30 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 779/8867 [01:40<17:22,  7.75it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:31 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:31 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:31 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 789/8867 [01:41<17:20,  7.76it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:33 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:33 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:33 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 799/8867 [01:42<17:18,  7.77it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:34 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:34 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:34 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 809/8867 [01:44<17:16,  7.78it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:35 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:35 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:35 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 819/8867 [01:45<17:14,  7.78it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:36 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:36 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:36 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 829/8867 [01:46<17:12,  7.79it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:37 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:37 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:08:37 nemo_logging:393] predicted:\n",
      "Epoch 0:   9%| | 839/8867 [01:47<17:09,  7.80it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:39 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:39 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:39 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 849/8867 [01:48<17:07,  7.81it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:40 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:40 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:40 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 859/8867 [01:50<17:06,  7.80it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:41 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:41 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:41 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 869/8867 [01:51<17:05,  7.80it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:42 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:42 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:42 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 879/8867 [01:52<17:03,  7.81it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:44 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:44 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:44 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 889/8867 [01:53<17:01,  7.81it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:45 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:45 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:45 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 899/8867 [01:55<17:00,  7.81it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:46 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:46 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:46 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 909/8867 [01:56<17:01,  7.79it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:48 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:48 nemo_logging:393] reference:          \n",
      "[NeMo I 2025-01-10 10:08:48 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 919/8867 [01:57<16:59,  7.80it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:49 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:49 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:49 nemo_logging:393] predicted:\n",
      "Epoch 0:  10%| | 929/8867 [01:58<16:56,  7.81it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:50 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:50 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:50 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 939/8867 [02:00<16:58,  7.79it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:52 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:52 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:52 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 949/8867 [02:01<16:57,  7.79it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:53 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:53 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:53 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 959/8867 [02:03<16:55,  7.79it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:54 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:54 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:54 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 969/8867 [02:04<16:53,  7.79it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:55 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:55 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:55 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 979/8867 [02:05<16:51,  7.80it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:56 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:56 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:08:56 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 989/8867 [02:06<16:50,  7.80it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:58 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:58 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:58 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 999/8867 [02:08<16:48,  7.80it/s, v_num=6-44, train_step_timing[NeMo I 2025-01-10 10:08:59 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:08:59 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:08:59 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 1009/8867 [02:09<16:47,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:00 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:00 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:00 nemo_logging:393] predicted:\n",
      "Epoch 0:  11%| | 1019/8867 [02:10<16:46,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:02 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:02 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:02 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1029/8867 [02:11<16:44,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:03 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:03 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:09:03 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1039/8867 [02:13<16:42,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:04 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:04 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:04 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1049/8867 [02:14<16:42,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:06 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:06 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:06 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1059/8867 [02:15<16:42,  7.79it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:07 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:07 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:07 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1069/8867 [02:17<16:40,  7.79it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:08 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:08 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:09:08 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1079/8867 [02:18<16:38,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:09 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:09 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:09 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1089/8867 [02:19<16:36,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:11 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:11 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:11 nemo_logging:393] predicted:\n",
      "Epoch 0:  12%| | 1099/8867 [02:20<16:35,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:12 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:12 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:12 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1109/8867 [02:22<16:33,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:13 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:13 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:13 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1119/8867 [02:23<16:31,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:14 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:14 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:14 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1129/8867 [02:25<16:33,  7.79it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:16 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:16 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:16 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1139/8867 [02:26<16:31,  7.79it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:17 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:17 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:17 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1149/8867 [02:27<16:29,  7.80it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:18 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:18 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:18 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1159/8867 [02:28<16:27,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:19 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:19 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:19 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1169/8867 [02:29<16:25,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:21 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:21 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:21 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1179/8867 [02:30<16:23,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:22 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:22 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:22 nemo_logging:393] predicted:\n",
      "Epoch 0:  13%|| 1189/8867 [02:32<16:22,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:23 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:23 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:23 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1199/8867 [02:33<16:21,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:24 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:24 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:24 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1209/8867 [02:34<16:20,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:26 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:26 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:26 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1219/8867 [02:35<16:18,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:27 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:27 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:27 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1229/8867 [02:37<16:16,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:28 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:28 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:28 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1239/8867 [02:38<16:15,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:30 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:30 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:30 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1249/8867 [02:39<16:15,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:31 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:31 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:31 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1259/8867 [02:41<16:13,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:32 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:32 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:32 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1269/8867 [02:42<16:12,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:33 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:33 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:33 nemo_logging:393] predicted:\n",
      "Epoch 0:  14%|| 1279/8867 [02:43<16:10,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:35 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:35 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:35 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1289/8867 [02:44<16:09,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:36 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:36 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:36 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1299/8867 [02:46<16:08,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:37 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:37 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:37 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1309/8867 [02:47<16:06,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:38 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:38 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:38 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1319/8867 [02:48<16:05,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:40 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:40 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:40 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1329/8867 [02:50<16:04,  7.81it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:41 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:41 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:41 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1339/8867 [02:51<16:03,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:42 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:42 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:42 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1349/8867 [02:52<16:01,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:43 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:43 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:43 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1359/8867 [02:53<16:00,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:45 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:45 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:45 nemo_logging:393] predicted:\n",
      "Epoch 0:  15%|| 1369/8867 [02:55<15:58,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:46 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:46 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:09:46 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1379/8867 [02:56<15:57,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:47 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:47 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:47 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1389/8867 [02:57<15:55,  7.83it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:49 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:49 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:49 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1399/8867 [02:58<15:54,  7.82it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:50 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:50 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:50 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1409/8867 [02:59<15:52,  7.83it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:51 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:51 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:09:51 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1419/8867 [03:01<15:50,  7.83it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:52 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:52 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:52 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1429/8867 [03:02<15:49,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:53 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:53 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:53 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1439/8867 [03:03<15:48,  7.83it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:55 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:55 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:55 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1449/8867 [03:04<15:47,  7.83it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:56 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:56 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:09:56 nemo_logging:393] predicted:\n",
      "Epoch 0:  16%|| 1459/8867 [03:06<15:45,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:57 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:57 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:57 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1469/8867 [03:07<15:43,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:09:58 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:09:58 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:09:58 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1479/8867 [03:08<15:42,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:00 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:00 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:10:00 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1489/8867 [03:09<15:41,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:01 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:01 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:01 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1499/8867 [03:11<15:40,  7.83it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:02 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:02 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:10:02 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1509/8867 [03:12<15:39,  7.83it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:04 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:04 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:04 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1519/8867 [03:13<15:37,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:05 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:05 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:10:05 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1529/8867 [03:15<15:36,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:06 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:06 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:06 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1539/8867 [03:16<15:34,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:07 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:07 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:10:07 nemo_logging:393] predicted:\n",
      "Epoch 0:  17%|| 1549/8867 [03:17<15:33,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:09 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:09 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:09 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1559/8867 [03:18<15:31,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:10 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:10 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:10:10 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1569/8867 [03:19<15:29,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:11 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:11 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:11 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1579/8867 [03:21<15:28,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:12 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:12 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:12 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1589/8867 [03:22<15:27,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:13 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:13 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:10:13 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1599/8867 [03:23<15:25,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:15 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:15 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:15 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1609/8867 [03:25<15:26,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:16 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:16 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:16 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1619/8867 [03:26<15:24,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:18 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:18 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:18 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1629/8867 [03:27<15:23,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:19 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:19 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:19 nemo_logging:393] predicted:\n",
      "Epoch 0:  18%|| 1639/8867 [03:29<15:21,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:20 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:20 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:20 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1649/8867 [03:30<15:20,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:21 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:21 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:21 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1659/8867 [03:31<15:18,  7.84it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:22 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:22 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:22 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1669/8867 [03:32<15:16,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:24 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:24 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:24 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1679/8867 [03:33<15:15,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:25 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:25 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:25 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1689/8867 [03:34<15:13,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:26 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:26 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:26 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1699/8867 [03:36<15:12,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:27 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:27 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:10:27 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1709/8867 [03:37<15:11,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:29 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:29 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:29 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1719/8867 [03:38<15:09,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:30 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:30 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:30 nemo_logging:393] predicted:\n",
      "Epoch 0:  19%|| 1729/8867 [03:40<15:08,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:31 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:31 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:31 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1739/8867 [03:41<15:06,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:32 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:32 nemo_logging:393] reference:       \n",
      "[NeMo I 2025-01-10 10:10:32 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1749/8867 [03:42<15:05,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:34 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:34 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:34 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1759/8867 [03:44<15:05,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:35 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:35 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:35 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1769/8867 [03:45<15:03,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:36 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:36 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:36 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1779/8867 [03:46<15:02,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:38 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:38 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:38 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1789/8867 [03:47<15:01,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:39 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:39 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:10:39 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1799/8867 [03:48<14:59,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:40 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:40 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:40 nemo_logging:393] predicted:\n",
      "Epoch 0:  20%|| 1809/8867 [03:50<14:57,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:41 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:41 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:41 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1819/8867 [03:51<14:56,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:42 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:42 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:42 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1829/8867 [03:52<14:55,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:44 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:44 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:10:44 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1839/8867 [03:53<14:54,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:45 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:45 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:45 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1849/8867 [03:55<14:52,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:46 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:46 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:46 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1859/8867 [03:56<14:51,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:48 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:48 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:48 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1869/8867 [03:57<14:50,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:49 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:49 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:10:49 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1879/8867 [03:58<14:48,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:50 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:50 nemo_logging:393] reference:        \n",
      "[NeMo I 2025-01-10 10:10:50 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1889/8867 [04:00<14:47,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:51 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:51 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:51 nemo_logging:393] predicted:\n",
      "Epoch 0:  21%|| 1899/8867 [04:01<14:46,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:52 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:52 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:10:52 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1909/8867 [04:02<14:44,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:54 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:54 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:54 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1919/8867 [04:03<14:42,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:55 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:55 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:10:55 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1929/8867 [04:05<14:41,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:56 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:56 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:56 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1939/8867 [04:06<14:40,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:57 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:57 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:57 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1949/8867 [04:07<14:39,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:10:59 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:10:59 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:10:59 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1959/8867 [04:08<14:38,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:00 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:00 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:00 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1969/8867 [04:10<14:37,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:02 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:02 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:02 nemo_logging:393] predicted:\n",
      "Epoch 0:  22%|| 1979/8867 [04:12<14:37,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:03 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:03 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:03 nemo_logging:393] predicted: \n",
      "Epoch 0:  22%|| 1989/8867 [04:13<14:36,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:04 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:04 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:11:04 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 1999/8867 [04:14<14:34,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:06 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:06 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:06 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2009/8867 [04:15<14:33,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:07 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:07 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:07 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2019/8867 [04:17<14:31,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:08 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:08 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:08 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2029/8867 [04:18<14:31,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:09 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:09 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:09 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2039/8867 [04:19<14:29,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:11 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:11 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:11 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2049/8867 [04:20<14:27,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:12 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:12 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:12 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2059/8867 [04:21<14:26,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:13 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:13 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:13 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2069/8867 [04:23<14:25,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:14 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:14 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:14 nemo_logging:393] predicted:\n",
      "Epoch 0:  23%|| 2079/8867 [04:24<14:23,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:16 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:16 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:16 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2089/8867 [04:25<14:22,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:17 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:17 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:17 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2099/8867 [04:26<14:20,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:18 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:18 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:18 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2109/8867 [04:28<14:19,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:19 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:19 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:19 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2119/8867 [04:29<14:18,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:21 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:21 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:21 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2129/8867 [04:30<14:17,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:22 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:22 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:22 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2139/8867 [04:32<14:16,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:23 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:23 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:23 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2149/8867 [04:33<14:14,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:24 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:24 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:24 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2159/8867 [04:34<14:13,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:26 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:26 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:26 nemo_logging:393] predicted:\n",
      "Epoch 0:  24%|| 2169/8867 [04:35<14:11,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:27 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:27 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:27 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2179/8867 [04:37<14:10,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:28 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:28 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:28 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2189/8867 [04:38<14:08,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:29 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:29 nemo_logging:393] reference:            \n",
      "[NeMo I 2025-01-10 10:11:29 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2199/8867 [04:39<14:08,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:31 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:31 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:31 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2209/8867 [04:41<14:07,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:32 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:32 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:32 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2219/8867 [04:42<14:05,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:33 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:33 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:33 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2229/8867 [04:43<14:04,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:35 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:35 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:35 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2239/8867 [04:44<14:03,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:36 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:36 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:11:36 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2249/8867 [04:46<14:01,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:37 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:37 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:37 nemo_logging:393] predicted:\n",
      "Epoch 0:  25%|| 2259/8867 [04:47<14:00,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:38 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:38 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:38 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2269/8867 [04:48<13:59,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:40 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:40 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:40 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2279/8867 [04:49<13:57,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:41 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:41 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:41 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2289/8867 [04:50<13:56,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:42 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:42 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:42 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2299/8867 [04:52<13:54,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:43 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:43 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:43 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2309/8867 [04:53<13:53,  7.87it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:45 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:45 nemo_logging:393] reference:   \n",
      "[NeMo I 2025-01-10 10:11:45 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2319/8867 [04:54<13:52,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:46 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:46 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:46 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2329/8867 [04:56<13:51,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:47 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:47 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:47 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2339/8867 [04:57<13:50,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:49 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:49 nemo_logging:393] reference:  \n",
      "[NeMo I 2025-01-10 10:11:49 nemo_logging:393] predicted:\n",
      "Epoch 0:  26%|| 2349/8867 [04:59<13:49,  7.86it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:50 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:50 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:50 nemo_logging:393] predicted:\n",
      "Epoch 0:  27%|| 2359/8867 [05:00<13:48,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:51 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:51 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:51 nemo_logging:393] predicted:\n",
      "Epoch 0:  27%|| 2369/8867 [05:01<13:47,  7.85it/s, v_num=6-44, train_step_timin[NeMo I 2025-01-10 10:11:53 nemo_logging:393] \n",
      "    \n",
      "[NeMo I 2025-01-10 10:11:53 nemo_logging:393] reference: \n",
      "[NeMo I 2025-01-10 10:11:53 nemo_logging:393] predicted:\n",
      "Epoch 0:  27%|| 2373/8867 [05:02<13:47,  7.85it/s, v_num=6-44, train_step_timin"
     ]
    }
   ],
   "source": [
    "!python NeMo/examples/asr/asr_ctc/speech_to_text_ctc_bpe.py \\\n",
    "--config-path=\"/home/jenny/conformer/cofig\" --config-name=\"config\" \\\n",
    "model.train_ds.manifest_filepath=\"dataset/manifest_labels_train.json\" \\\n",
    "model.validation_ds.manifest_filepath=\"dataset/manifest_labels_val.json\" \\\n",
    "model.test_ds.manifest_filepath=\"dataset/manifest_remaining_test.json\" \\\n",
    "model.tokenizer.dir=\"tokens/tokenizer_spe_unigram_v128_max_200\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5198077,
     "sourceId": 8672890,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6408831,
     "sourceId": 10349570,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
